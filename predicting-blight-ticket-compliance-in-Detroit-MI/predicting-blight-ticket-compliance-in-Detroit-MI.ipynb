{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsharmon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (11,12,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read in all of the relevant csv files\n",
    "train = pd.read_csv('data/train.csv', encoding = \"ISO-8859-1\")\n",
    "addresses = pd.read_csv('data/addresses.csv')\n",
    "latlons = pd.read_csv('data/latlons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NULL compliance values to leave binary classification problem\n",
    "train.dropna(subset=['compliance'], inplace=True)\n",
    "\n",
    "# Drop a number of features for reasons listed:\n",
    "# Removing collection status and compliance detail to avoid data leakage. Removing violator name because\n",
    "# it doesn't seem like that would provide much generalizable information. Removing information about violation\n",
    "# location, replacing with latitude/longitude. Remove fine_amount, admin_fee, state_fee as they're rolled into\n",
    "# judgment_amount, but keep the late_fee, discount_amount, and clean_up_cost. Maybe get rid of clean_up_cost\n",
    "# later. Remove other columns related to payment, prevent data leakage. Removing mailing address st name and\n",
    "# zip code, as well as non_us_str_code. Removing violation_description as it should overlap with violation_code.\n",
    "# Removing city as I was killing the kernel trying to one hot encode it. Removing grafitti_status as the entire\n",
    "# column was NaN.\n",
    "droplist = ['violator_name', 'violation_street_number', 'violation_street_name', \n",
    "            'violation_zip_code', 'fine_amount','admin_fee','state_fee',\n",
    "            'payment_amount', 'payment_date', 'payment_status', 'balance_due',\n",
    "            'collection_status', 'compliance_detail', \n",
    "            'mailing_address_str_name', 'zip_code', 'non_us_str_code',\n",
    "            'violation_description', 'city', 'grafitti_status']\n",
    "train.drop(droplist, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge address and lat lon, then merge into main df\n",
    "addFull = pd.merge(addresses, latlons, on='address')\n",
    "\n",
    "# Remove address as the info there is already covered by lat and lon\n",
    "X = pd.merge(train, addFull, on='ticket_id').drop('address', axis=1)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categoricalCols = ['agency_name', 'state', 'country', 'disposition', \n",
    "                   'violation_code', 'inspector_name']\n",
    "\n",
    "for col in categoricalCols:\n",
    "    X = pd.concat([X.drop(col, axis=1), pd.get_dummies(X[col])], axis=1)\n",
    "\n",
    "# Convert datetime columns to seconds since the epoch\n",
    "dateCols = ['ticket_issued_date', 'hearing_date']\n",
    "\n",
    "for col in dateCols:\n",
    "    X[col] = pd.to_datetime(X[col])\n",
    "    X[col] = (X[col] - datetime.datetime(1970,1,1)).dt.total_seconds()\n",
    "\n",
    "# Introduce new feature - time from ticket issue to hearing date, remove old cols\n",
    "X['time_to_hearing'] = X['hearing_date'] - X['ticket_issued_date']\n",
    "X.drop(['ticket_issued_date', 'hearing_date'], axis=1, inplace=True)\n",
    "    \n",
    "# Do a final dropna\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "# Get target values, then drop col from features\n",
    "y = X['compliance']\n",
    "X.drop('compliance', axis=1, inplace=True)\n",
    "\n",
    "# Remove ticket id as this likely is not informative for future cases\n",
    "X.drop('ticket_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9904943772544027\n",
      "Test accuracy: 0.9419747428455036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the training data. Won't do this for actual function, but is useful here for evaluation.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "rfc = RandomForestClassifier(max_features = 8, n_estimators = 10).fit(X_train, y_train)\n",
    "\n",
    "# Actually looks surpisingly good!!\n",
    "print('Training accuracy: {}'.format(rfc.score(X_train, y_train)))\n",
    "print('Test accuracy: {}'.format(rfc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-compliant       0.95      0.99      0.97     36425\n",
      "    compliant       0.75      0.30      0.43      2851\n",
      "\n",
      "    micro avg       0.94      0.94      0.94     39276\n",
      "    macro avg       0.85      0.64      0.70     39276\n",
      " weighted avg       0.93      0.94      0.93     39276\n",
      "\n",
      "AUC: 0.7704324916277614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "\n",
    "print(classification_report(y_test, rfc.predict(X_test), target_names=['non-compliant', 'compliant']))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(np.asarray(y_test), rfc.predict_proba(X_test)[:,1])\n",
    "print('AUC: {}'.format(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>time_to_hearing</th>\n",
       "      <td>0.163937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lon</th>\n",
       "      <td>0.155597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>0.155231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mailing_address_str_number</th>\n",
       "      <td>0.150370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>late_fee</th>\n",
       "      <td>0.059774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Responsible by Default</th>\n",
       "      <td>0.051841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judgment_amount</th>\n",
       "      <td>0.041099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discount_amount</th>\n",
       "      <td>0.032909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Responsible by Determination</th>\n",
       "      <td>0.022304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Responsible by Admission</th>\n",
       "      <td>0.021569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              importance\n",
       "time_to_hearing                 0.163937\n",
       "lon                             0.155597\n",
       "lat                             0.155231\n",
       "mailing_address_str_number      0.150370\n",
       "late_fee                        0.059774\n",
       "Responsible by Default          0.051841\n",
       "judgment_amount                 0.041099\n",
       "discount_amount                 0.032909\n",
       "Responsible by Determination    0.022304\n",
       "Responsible by Admission        0.021569"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_, index = X_train.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances.iloc[0:10, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
