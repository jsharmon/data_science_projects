{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting blight ticket compliance in Detroit, MI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data sets used and the problem that this code attempts to solve were provided as part of a Coursera course $-$ Applied Machine Learning in Python. Given that the assignment was relatively free of constraints $-$ train a model to produce an AUC of 0.7 or better on a previously unseen test set, without using MLPs $-$ I decided to put the code on my personal Github, as I feel this is only one of a great many possible answers and that the problem itself is interesting.\n",
    "\n",
    "To summarize the problem, blight refers to dilapidated housing or structures that may be unsightly at best and unsafe or abandoned at worst. Blight tickets are intended to hold property owners accountable for maintaining an acceptable level of upkeep by levying a fine at those who allow their property to fall into disrepair. These fines are not always paid, however, which forms the basis of the primary question for this bite-sized project $-$ can a model be trained to accurately predict which individuals will comply in paying the fine? More information about blight tickets can be found [here](https://detroitmi.gov/departments/department-appeals-and-hearings/blight-ticket-information).\n",
    "\n",
    "The data set used here was pulled directly from Coursera, who in turn obtained all data used from the [Detroit Open Data Portal](https://data.detroitmi.gov/). It contains information about all tickets issued from 2004-2011. Additionally, two other files allow for an easy conversion from text-based addresses to latitudes and longitudes.\n",
    "\n",
    "<br>\n",
    "\n",
    "__The file 'train.csv' contains the following fields__ (from Coursera):\n",
    "\n",
    "_Information about the ticket, those who issued it_:\n",
    ">ticket_id - unique identifier for tickets<br>\n",
    "agency_name - Agency that issued the ticket<br>\n",
    "inspector_name - Name of inspector that issued the ticket<br>\n",
    "\n",
    "_Information about the violator_:\n",
    ">violator_name - Name of the person/organization that the ticket was issued to<br>\n",
    "violation_street_number, violation_street_name, violation_zip_code - Address where the violation occurred<br>\n",
    "mailing_address_str_number, mailing_address_str_name, city, state, zip_code, non_us_str_code, country - Mailing address of the violator<br>\n",
    "\n",
    "_Relevant dates_:\n",
    ">ticket_issued_date - Date and time the ticket was issued<br>\n",
    "hearing_date - Date and time the violator's hearing was scheduled<br>\n",
    "\n",
    "_Details about the violation and judgment_:\n",
    ">violation_code, violation_description - Type of violation<br>\n",
    "disposition - Judgment and judgment type<br>\n",
    "\n",
    "_Financial details_:\n",
    ">fine_amount - Violation fine amount, excluding fees<br>\n",
    "admin_fee - 20 USD fee assigned to responsible judgments<br>\n",
    "state_fee - 10 USD fee assigned to responsible judgments<br>\n",
    "late_fee - 10% fee assigned to responsible judgments<br>\n",
    "discount_amount - discount applied, if any<br>\n",
    "clean_up_cost - DPW clean-up or graffiti removal cost<br>\n",
    "judgment_amount - Sum of all fines and fees<br>\n",
    "\n",
    "_Misc_:\n",
    ">grafitti_status - Flag for graffiti violations<br>\n",
    "\n",
    "_Payment and compliance information_:\n",
    ">payment_amount - Amount paid, if any<br>\n",
    "payment_date - Date payment was made, if it was received<br>\n",
    "payment_status - Current payment status as of Feb 1 2017<br>\n",
    "balance_due - Fines and fees still owed<br>\n",
    "collection_status - Flag for payments in collections<br>\n",
    "compliance<br>\n",
    " Null = Not responsible<br>\n",
    " 0 = Responsible, non-compliant<br>\n",
    " 1 = Responsible, compliant<br>\n",
    "compliance_detail - More information on why each ticket was marked compliant or non-compliant<br>\n",
    "\n",
    "<br>\n",
    "I have elected to use a random forest classifier for this problem as it allows me to easily handle a variety of input types, does not require scaling of the input data, and can easily provide a list of the features that the model considers to be the most important, an attribute that I find useful during feature selection and model refinement. Data cleaning and feature selection decisions will be explained in markdown preceding the relevant cells.\n",
    "\n",
    "In conclusion, it appears that the most important features are the latitude and longitude of the dwelling. This may suggest that blight tickets are often levied at those who own structures in poorer regions of the city, and are therefore less able to pay; cross referencing with another data set that provides information about the geographical distribution of wealth in the city may provide more insight into this point. Another interesting finding is that two of the most important features are the judgment amount $-$ the total fine levied against the property owner $-$ and the discount amount. The judgment amount may indicate that individuals are unable or simply unwilling to pay larger fees, whereas the discount amount may play a more psychological role in the outcome $-$ if individuals feel as if the fee is reduced, they may be less upset about having received a ticket, and may therefore be more likely to pay it. If the city of Detroit desires to increase compliance, it may be worth decreasing the magnitude of fees levied for each offense or to increase the discount amount. If a smaller fine increases compliance, that could possibly increase revenue despite the decreased revenue from each individual blight ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all of the relevant csv files\n",
    "train = pd.read_csv('data/train.csv', encoding = \"ISO-8859-1\", low_memory=False)\n",
    "addresses = pd.read_csv('data/addresses.csv')\n",
    "latlons = pd.read_csv('data/latlons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NULL compliance values to leave binary classification problem\n",
    "train.dropna(subset=['compliance'], inplace=True)\n",
    "\n",
    "# Drop a number of features for reasons listed:\n",
    "# Removing collection status and compliance detail to avoid data leakage. Removing violator name because\n",
    "# it doesn't seem like that would provide much generalizable information. Removing information about violation\n",
    "# location, replacing with latitude/longitude. Remove fine_amount, admin_fee, state_fee as they're rolled into\n",
    "# judgment_amount, but keep the late_fee, discount_amount, and clean_up_cost. Maybe get rid of clean_up_cost\n",
    "# later. Remove other columns related to payment, prevent data leakage. Removing mailing address st name and\n",
    "# zip code, as well as non_us_str_code. Removing violation_description as it should overlap with violation_code.\n",
    "# Removing city as I was killing the kernel trying to one hot encode it. Removing grafitti_status as the entire\n",
    "# column was NaN. Had previously tried to do something clever by finding and using the time to hearing from the\n",
    "# ticket_issued_date and hearing_date columns, but this provided odd data. For example, some values were less than\n",
    "# zero...which is impossible. Removing late fee to get rid of data leakage.\n",
    "droplist = ['violator_name', 'violation_street_number', 'violation_street_name', \n",
    "            'violation_zip_code', 'fine_amount','admin_fee','state_fee',\n",
    "            'payment_amount', 'payment_date', 'payment_status', 'balance_due',\n",
    "            'collection_status', 'compliance_detail', \n",
    "            'mailing_address_str_name', 'zip_code', 'non_us_str_code',\n",
    "            'violation_description', 'city', 'grafitti_status', 'mailing_address_str_number',\n",
    "            'ticket_issued_date', 'hearing_date', 'late_fee']\n",
    "train.drop(droplist, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge address and lat lon, then merge into main df\n",
    "addFull = pd.merge(addresses, latlons, on='address')\n",
    "\n",
    "# Remove address as the info there is already covered by lat and lon\n",
    "X = pd.merge(train, addFull, on='ticket_id').drop('address', axis=1)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categoricalCols = ['agency_name', 'state', 'country', 'disposition', \n",
    "                   'violation_code', 'inspector_name']\n",
    "\n",
    "for col in categoricalCols:\n",
    "    X = pd.concat([X.drop(col, axis=1), pd.get_dummies(X[col])], axis=1)\n",
    "\n",
    "# Introduce new feature - time from ticket issue to hearing date, remove old cols, drop odd vals\n",
    "#X['time_to_hearing'] = (pd.to_datetime(X['hearing_date']) - pd.to_datetime(X['ticket_issued_date'])).dt.total_seconds()\n",
    "#X.drop(['ticket_issued_date', 'hearing_date'], axis=1, inplace=True)\n",
    "#X = X[X['time_to_hearing'] > 0]\n",
    "#X = X[(np.abs(stats.zscore(X['time_to_hearing'])) < 3)] # drop outliers\n",
    "    \n",
    "# Do a final dropna\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "# Get target values, then drop col from features\n",
    "y = X['compliance']\n",
    "X.drop('compliance', axis=1, inplace=True)\n",
    "\n",
    "# Remove ticket id as this likely is not informative for future cases\n",
    "X.drop('ticket_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9873569736798212\n",
      "Test accuracy: 0.9317988491368526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the training data. Won't do this for actual function, but is useful here for evaluation.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "rfc = RandomForestClassifier(max_features = 8, n_estimators = 10).fit(X_train, y_train)\n",
    "\n",
    "# Actually looks surpisingly good!!\n",
    "print('Training accuracy: {}'.format(rfc.score(X_train, y_train)))\n",
    "print('Test accuracy: {}'.format(rfc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-compliant       0.95      0.98      0.96     37056\n",
      "    compliant       0.57      0.27      0.37      2914\n",
      "\n",
      "    micro avg       0.93      0.93      0.93     39970\n",
      "    macro avg       0.76      0.63      0.67     39970\n",
      " weighted avg       0.92      0.93      0.92     39970\n",
      "\n",
      "AUC: 0.7415297604071465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "\n",
    "print(classification_report(y_test, rfc.predict(X_test), target_names=['non-compliant', 'compliant']))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(np.asarray(y_test), rfc.predict_proba(X_test)[:,1])\n",
    "print('AUC: {}'.format(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lon</th>\n",
       "      <td>0.306876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>0.305641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judgment_amount</th>\n",
       "      <td>0.083803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discount_amount</th>\n",
       "      <td>0.060611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Responsible by Default</th>\n",
       "      <td>0.043075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Responsible by Determination</th>\n",
       "      <td>0.032080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Responsible by Admission</th>\n",
       "      <td>0.025173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Responsible (Fine Waived) by Deter</th>\n",
       "      <td>0.005514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>0.003961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9-1-36(a)</th>\n",
       "      <td>0.003501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    importance\n",
       "lon                                   0.306876\n",
       "lat                                   0.305641\n",
       "judgment_amount                       0.083803\n",
       "discount_amount                       0.060611\n",
       "Responsible by Default                0.043075\n",
       "Responsible by Determination          0.032080\n",
       "Responsible by Admission              0.025173\n",
       "Responsible (Fine Waived) by Deter    0.005514\n",
       "MI                                    0.003961\n",
       "9-1-36(a)                             0.003501"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_, index = X_train.columns,\n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances.iloc[0:10, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
